{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Training Average minibatch 1000 loss: 3.418\n",
      "Training Average minibatch 2000 loss: 3.171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e6625653b40c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_bleu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mminibatch_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mminibatch_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-e6625653b40c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mmin_val_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0mdecoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mbleu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0mdecoder_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmin_val_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e6625653b40c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(encoder, decoder, feature, labels, training, encoder_optimizer, decoder_optimizer)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;31m#             epoch_bleu += batchBLEU(decoder_charid,labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.twitter_data import data\n",
    "from data.twitter_data.data import SOS,EOS,UNK\n",
    "import data_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "config ={}\n",
    "config['twitter_datapath'] = 'data/twitter_data/'\n",
    "# config['vocab_size']\n",
    "config['emb_dim'] = 300\n",
    "config['hid_size'] = 1024\n",
    "config['num_layers'] =3\n",
    "config['num_epoch'] = 200\n",
    "config['batch_size'] = 32\n",
    "config['teaching'] = True\n",
    "config['teacher_forcing_ratio'] = 1\n",
    "config['learning rate'] = 0.001\n",
    "config['max_len'] = 20\n",
    "config['model_dir']= 'save/'\n",
    "\n",
    "\n",
    "metadata, idx_q, idx_a = data.load_data(config['twitter_datapath'])\n",
    "SOS_token = metadata['w2idx'][SOS]\n",
    "EOS_token = metadata['w2idx'][EOS]\n",
    "UNK_token = metadata['w2idx'][UNK]\n",
    "PAD_token = 0\n",
    "config['vocab_size'] = len(metadata['idx2w'])\n",
    "\n",
    "criterion  = nn.CrossEntropyLoss(ignore_index = EOS_token)\n",
    "(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(idx_q, idx_a)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 4, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = config['vocab_size']\n",
    "        self.emb_dim  = config['emb_dim']\n",
    "        self.hidden_size = config['hid_size']\n",
    "        self.num_layers = config['num_layers']\n",
    "        self.time_step = config['max_len']\n",
    "        self.embedding = nn.Embedding(self.input_size, self.emb_dim)\n",
    "        self.rnn = nn.GRU(self.emb_dim, self.hidden_size,num_layers=self.num_layers,batch_first = True)\n",
    "      \n",
    "    def forward(self,input_data,hidden = None):\n",
    "        time_step = config['max_len']\n",
    "        embedded = self.embedding(input_data)\n",
    "        output = embedded\n",
    "        output, hidden = self.rnn(output,hidden)\n",
    "        return output,hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(1,self.time_step , self.hidden_size, device=computing_device)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_size = config['vocab_size']\n",
    "        self.output_size = self.input_size\n",
    "        self.emb_dim  = config['emb_dim']\n",
    "        self.num_layers = config['num_layers']\n",
    "        self.hidden_size = config['hid_size']\n",
    "        self.embedding = nn.Embedding(self.input_size, self.emb_dim)\n",
    "        self.rnn = nn.GRU(self.emb_dim, self.hidden_size,num_layers=self.num_layers,batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_data, hidden,encoder_outputs):\n",
    "        batch_size = input_data.shape[1]\n",
    "        time_step = input_data.shape[0]\n",
    "        output = self.embedding(input_data)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output,hidden\n",
    "\n",
    "    def init_hidden(self,hidden):\n",
    "        return hidden\n",
    "\n",
    "def batchBLEU(output,target):\n",
    "    score = 0.0\n",
    "    batch_size = len(target)\n",
    "    output= output.detach().cpu().numpy()\n",
    "    target= target.cpu().numpy()\n",
    "    for i in range(batch_size):\n",
    "        score+=seqBLEU(output[i],target[i])\n",
    "    return score/batch_size\n",
    "    \n",
    "def seqBLEU(candidate,reference):\n",
    "    reference = reference.tolist()\n",
    "    endidx = reference.index(EOS_token)\n",
    "    reference = reference[1:endidx]\n",
    "    counts = Counter(candidate)\n",
    "    if not counts:\n",
    "        return 0\n",
    "    max_counts = {}\n",
    "    reference_counts = Counter(reference)\n",
    "    for ngram in counts:\n",
    "        max_counts[ngram] = max(max_counts.get(ngram, 0), reference_counts[ngram])\n",
    "    clipped_counts = dict((ngram, min(count, max_counts[ngram])) for ngram, count in counts.items())\n",
    "    return sum(clipped_counts.values()) / sum(counts.values())\n",
    "    \n",
    "def train():\n",
    "    encoder_path= config['model_dir']+'encoder'+'.ckpt'\n",
    "    decoder_path= config['model_dir']+'decoder'+'.ckpt'\n",
    "    encoder = Encoder(config)\n",
    "    decoder = Decoder(config)\n",
    "    encoder.to(computing_device)\n",
    "    decoder.to(computing_device)\n",
    "    \n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(),lr = config['learning rate'])\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(),lr = config['learning rate'])\n",
    "    \n",
    "    min_val_loss=100\n",
    "    for epoch in range(config['num_epoch']):\n",
    "        _,train_loss = run_epoch(encoder,decoder,trainX,trainY,training=True,encoder_optimizer=encoder_optimizer,\\\n",
    "                                 decoder_optimizer = decoder_optimizer)\n",
    "        bleu,val_loss = run_epoch(encoder,decoder,validX,validY,training=False,encoder_optimizer=encoder_optimizer,\\\n",
    "                                 decoder_optimizer = decoder_optimizer)\n",
    "        if val_loss<min_val_loss:\n",
    "            min_val_loss=val_loss\n",
    "            torch.save(encoder.state_dict(),encoder_path)\n",
    "            torch.save(decoder.state_dict(),decoder_path)\n",
    "        print('Epoch %d,training loss: %.3f, validation loss:%.3f, BLEU score is:%.3f '%(epoch + 1, train_loss,val_loss,bleu))\n",
    "    \n",
    "    test_bleu,test_loss = run_epoch(encoder,decoder,testX,testY,training=False,encoder_optimizer=encoder_optimizer,\\\n",
    "                                 decoder_optimizer = decoder_optimizer)\n",
    "    print('Training completed after %d epochs, BLEU score is %.3f'%(epoch+1,test_bleu))\n",
    "#     print(test_bleu,test_loss)\n",
    "    return\n",
    "\n",
    "def run_epoch(encoder,decoder,feature,labels,training = False,encoder_optimizer=None,decoder_optimizer =None):\n",
    "    \n",
    "    batch_size = config['batch_size']\n",
    "    epoch_loss = 0\n",
    "    epoch_bleu = 0\n",
    "    N = 1000\n",
    "    N_minibatch_loss =0.0\n",
    "    data_loader = data_utils.batch_generator(feature,labels,batch_size = config['batch_size'])\n",
    "    \n",
    "    for minibatch_count, (data, labels) in enumerate(data_loader):\n",
    "        if training:\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            \n",
    "        data,labels = torch.tensor(data,dtype=torch.long),torch.tensor(labels,dtype=torch.long)\n",
    "        data,labels = data.to(computing_device),labels.to(computing_device)\n",
    "        encoder_outputs, encoder_hidden = encoder(data)\n",
    "        \n",
    "#         print(encoder_hidden.shape)\n",
    "#         assert 0==1\n",
    "        decoder_hidden = encoder_hidden\n",
    "        max_target_len = config['max_len']\n",
    "        loss = 0\n",
    "#         when training, 50% to teacher_forcing\n",
    "        \n",
    "        if training:\n",
    "            use_teacher_forcing = True if random.random() < config['teacher_forcing_ratio'] else False\n",
    "        \n",
    "        #when test or valid, don't use teacher_forcing\n",
    "        else: \n",
    "            use_teacher_forcing = False\n",
    "        \n",
    "        if config['teaching']:\n",
    "            use_teacher_forcing = True\n",
    "        \n",
    "        decoder_charid = torch.zeros_like(labels)\n",
    "        if use_teacher_forcing:\n",
    "            decoder_charid[:,0]= torch.LongTensor([[SOS_token for _ in range(batch_size)]]).to(computing_device).reshape(-1)\n",
    "            \n",
    "            batch_size = labels.shape[0]\n",
    "            target = labels[:,1:]\n",
    "            target = target.contiguous().view(-1)\n",
    "            \n",
    "            decoder_input = labels[:,:-1]\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            decoder_charid[:,1:]= torch.argmax(decoder_output,dim=2)\n",
    "            decoder_output = decoder_output.view(-1,config['vocab_size'])\n",
    "            loss = criterion(decoder_output,target)\n",
    "#             epoch_bleu += batchBLEU(decoder_charid,labels)\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                encoder_optimizer.step()\n",
    "                decoder_optimizer.step()\n",
    "            \n",
    "        else:\n",
    "            decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]]).to(computing_device).transpose(0,1)\n",
    "            decoder_charid[:,0] = decoder_input.reshape(-1)\n",
    "            batch_size = labels.shape[0]\n",
    "            target = labels[:,1:]\n",
    "            for t in range(max_target_len-1):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                output_id = torch.argmax(decoder_output.detach(),dim=2)\n",
    "                decoder_charid[:,t+1]\n",
    "                decoder_input = output_id\n",
    "                loss += F.cross_entropy(decoder_output.view(batch_size,-1), target[:,t], ignore_index=EOS_token)\n",
    "            if training:\n",
    "                loss.backward()\n",
    "                encoder_optimizer.step()\n",
    "                decoder_optimizer.step()\n",
    "                \n",
    "        epoch_bleu += batchBLEU(decoder_charid,labels)\n",
    "        epoch_loss+=loss.detach() \n",
    "        N_minibatch_loss+=loss.detach()\n",
    "#         loss = 0\n",
    "#         if minibatch_count >5000:\n",
    "#             print(minibatch_count)\n",
    "        if (minibatch_count%N ==0) and (minibatch_count!=0):\n",
    "#             print('hhahahahah',minibatch_count)\n",
    "            train_flag = \"Training\" if training else \"Validating/Testing\"\n",
    "            print(train_flag+' Average minibatch %d loss: %.3f'%(minibatch_count, N_minibatch_loss/N ))\n",
    "            N_minibatch_loss = 0\n",
    "    return epoch_bleu/minibatch_count,epoch_loss/minibatch_count\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader = data_utils.batch_generator(feature,labels,batch_size = config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
